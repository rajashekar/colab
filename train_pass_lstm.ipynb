{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajashekar/colab/blob/main/train_pass_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui5LcnD_oQNM",
        "outputId": "679d92e8-1289-4926-96d1-9409ba70380a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab/password\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Colab/password/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWjiNuSx9WIL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZvgDc7op-r9"
      },
      "outputs": [],
      "source": [
        "data = open('data/passwords_db.txt',).read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_LkTrk-qL4G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce90ad49-095a-48ee-80f9-34e45a82f123"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "178313552"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g02FJq9lqOgJ"
      },
      "outputs": [],
      "source": [
        "passwds = data.split(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8Aj6_E0q0hL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86f94a81-64b2-4987-c4eb-ecda6befaa7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18308617"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(passwds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko36Ziq0sbLj"
      },
      "source": [
        "# Vectorize the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weTKFR38C3TM"
      },
      "outputs": [],
      "source": [
        "vocab = sorted(list(set(''.join(passwds))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXfBF3yzDKDh",
        "outputId": "e73d00b1-4700-47da-c15d-c3608541a3ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RaM5ANgDWI_"
      },
      "outputs": [],
      "source": [
        "char_indices = dict((c, i) for i, c in enumerate(vocab))\n",
        "indices_char = dict((i, c) for i, c in enumerate(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhJ7DgosDb6y"
      },
      "outputs": [],
      "source": [
        "max_len = max(passwds, key=len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etgEVPzhoau8",
        "outputId": "92b29708-c6bb-48c8-d352-67fb5c7cacdf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8BEFv-TpNRx",
        "outputId": "d84b7287-9685-4e2a-c9a2-e495b81f807a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of passwords 18308617\n",
            "Passwords vocab size 95\n",
            "Max passwords length 50\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total number of passwords {len(passwds)}\")\n",
        "print(f\"Passwords vocab size {len(vocab)}\")\n",
        "print(f\"Max passwords length {len(max_len)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeTj4zUyt2a8"
      },
      "outputs": [],
      "source": [
        "input_text = [p[:-1] for p in passwds]\n",
        "target_text = [p[1:] for p in passwds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bMLxAb2vBQO",
        "outputId": "5a4d11be-52fd-456c-a1c6-516ba9cc302f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12STEVEN 12STEVE 2STEVEN\n"
          ]
        }
      ],
      "source": [
        "print(f\"{passwds[0]} {input_text[0]} {target_text[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuRwyhz8iqXM"
      },
      "outputs": [],
      "source": [
        "# Creating like below will blow memory\n",
        "\n",
        "# input_data = np.zeros( (len(passwds), len(max_len), len(vocab)) ,dtype='float32')\n",
        "# target_data = np.zeros( (len(passwds), len(max_len), len(vocab)) ,dtype='float32')\n",
        "\n",
        "# nearly took 17 GB of RAM memory for 1 million records\n",
        "# dataset has 14 million records\n",
        "# one_m_records = np.zeros( (1000000, 50, 95) ,dtype='float32')\n",
        "\n",
        "# clean memory\n",
        "# del one_m_records\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjiNNlf4xw6j"
      },
      "outputs": [],
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', char_level=True, lower=False)\n",
        "tokenizer.fit_on_texts(passwds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-moAS3B4y47S"
      },
      "outputs": [],
      "source": [
        "input_tensor = tokenizer.texts_to_sequences(input_text)\n",
        "input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWg3cv6QzJXc"
      },
      "outputs": [],
      "source": [
        "input_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgFpZ-1bzYTw"
      },
      "outputs": [],
      "source": [
        "target_tensor = tokenizer.texts_to_sequences(target_text)\n",
        "target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qbl3D-_zsPa7"
      },
      "outputs": [],
      "source": [
        "target_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1tMQ01PuNbK"
      },
      "outputs": [],
      "source": [
        "[''.join(i.split()) for i in tokenizer.sequences_to_texts(input_tensor[:5])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiPQKheBu7yL"
      },
      "outputs": [],
      "source": [
        "[''.join(i.split()) for i in tokenizer.sequences_to_texts(target_tensor[:5])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIpxA4h0Ae1X"
      },
      "outputs": [],
      "source": [
        "len(tokenizer.word_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DELyjgzKs0n1"
      },
      "source": [
        "# Split data into Train and Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyAhfR6ssmqb"
      },
      "outputs": [],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "# split to 70 30 \n",
        "input_tensor_train, input_tensor_rem, target_tensor_train, target_tensor_rem = train_test_split(input_tensor, target_tensor, test_size=0.3, shuffle=True)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train))\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "# split to 50 50\n",
        "input_tensor_val, input_tensor_test, target_tensor_val, target_tensor_test = train_test_split(input_tensor_rem, target_tensor_rem, test_size=0.5)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val))\n",
        "val_dataset = val_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_test, target_tensor_test))\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOmbRJLgJ4H3"
      },
      "outputs": [],
      "source": [
        "# For performance\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_dataset = val_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = test_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEMagILWzGUH"
      },
      "outputs": [],
      "source": [
        "example_input_batch, example_target_batch = next(iter(train_dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmweDXaczJAR"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "max_length_input = input_tensor.shape[1]\n",
        "max_length_output = target_tensor.shape[1]\n",
        "\n",
        "embedding_dim = vocab_size\n",
        "rnn_units = 2048\n",
        "\n",
        "print(f'Vocab size {vocab_size}')\n",
        "print(f\"Max input length {max_length_input}\")\n",
        "print(f\"Max input length {max_length_output}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor_train.shape"
      ],
      "metadata": {
        "id": "m7uqZ90nI-KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcMQyTxBA0-4"
      },
      "source": [
        "# Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8N429W2l-7e4"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = tf.keras.layers.LSTM(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.lstm.get_initial_state(x)\n",
        "    x, states_h, states_c = self.lstm(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states_h, states_c\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEFdG0KVAuIx"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neS_NEv5A6t1",
        "outputId": "15975233-4516-4517-c6c9-891ca7bebf04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 49, 96) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "# try model without training\n",
        "for input_example_batch, target_example_batch in train_dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntDNbbA3BB8g",
        "outputId": "da421f18-b95a-4720-f5f6-3aa1f4b85053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  9216      \n",
            "                                                                 \n",
            " lstm (LSTM)                 multiple                  17571840  \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  196704    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,777,760\n",
            "Trainable params: 17,777,760\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_example_batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbTOW1cEU0D_",
        "outputId": "5eec4bc9-fb69-49a9-ceef-4c3b6ca96259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(32, 49), dtype=int32, numpy=\n",
              "array([[ 6, 31, 10, ...,  0,  0,  0],\n",
              "       [ 3, 14,  4, ...,  0,  0,  0],\n",
              "       [15, 23,  9, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [ 6,  6, 14, ...,  0,  0,  0],\n",
              "       [10,  7,  5, ...,  0,  0,  0],\n",
              "       [26, 23,  9, ...,  0,  0,  0]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.categorical(example_batch_predictions[0], num_samples=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3nPZXjShD6",
        "outputId": "4f9d7b41-49a5-48e8-8170-2f9a050ebbbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(49, 1), dtype=int64, numpy=\n",
              "array([[69],\n",
              "       [79],\n",
              "       [38],\n",
              "       [66],\n",
              "       [15],\n",
              "       [81],\n",
              "       [95],\n",
              "       [23],\n",
              "       [46],\n",
              "       [32],\n",
              "       [69],\n",
              "       [85],\n",
              "       [ 6],\n",
              "       [44],\n",
              "       [87],\n",
              "       [65],\n",
              "       [35],\n",
              "       [24],\n",
              "       [54],\n",
              "       [40],\n",
              "       [81],\n",
              "       [49],\n",
              "       [67],\n",
              "       [56],\n",
              "       [14],\n",
              "       [65],\n",
              "       [95],\n",
              "       [35],\n",
              "       [76],\n",
              "       [56],\n",
              "       [33],\n",
              "       [10],\n",
              "       [94],\n",
              "       [39],\n",
              "       [ 6],\n",
              "       [14],\n",
              "       [60],\n",
              "       [53],\n",
              "       [19],\n",
              "       [22],\n",
              "       [ 2],\n",
              "       [63],\n",
              "       [78],\n",
              "       [10],\n",
              "       [82],\n",
              "       [32],\n",
              "       [17],\n",
              "       [ 2],\n",
              "       [ 7]])>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlfoER9aBFSc"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[tf.squeeze(tf.random.categorical(pred, num_samples=1), axis=-1).numpy() for pred in example_batch_predictions] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvTPQuR6UV0j",
        "outputId": "8f9283ab-037a-4dac-8286-22e97fabf022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([95, 41,  7, 13,  7,  6, 36, 49, 13, 27, 18, 68, 60, 37, 76, 85, 76,\n",
              "        71, 38, 35, 77, 32, 83, 29, 42, 63, 52, 93, 81, 67, 11, 92,  1, 55,\n",
              "        89, 46, 82, 79, 31, 14, 50, 31, 68, 36, 94,  4, 45, 54, 20]),\n",
              " array([69, 31, 28, 29, 47, 94, 91, 73,  2, 70, 68, 50, 73, 89, 31, 95, 80,\n",
              "        44, 45, 72,  1, 75, 36, 31, 84, 28, 10, 26, 84,  4, 25, 60, 93, 38,\n",
              "        35, 35, 74, 15, 64, 61, 10, 46, 12, 17, 70, 59, 55, 49, 24]),\n",
              " array([89, 83, 47, 47, 69, 63, 83, 58, 16, 52, 44, 95, 86, 94, 53,  5, 33,\n",
              "        76, 47, 83, 27, 36, 50, 66, 12, 57, 43, 29, 28,  6, 80, 63, 15, 64,\n",
              "        94, 71, 93, 90, 82, 12, 81, 39, 52, 68, 72, 24, 43, 56, 79]),\n",
              " array([76,  2, 26, 12, 43, 15, 74, 71, 58, 67, 23,  4, 77, 58, 49, 12, 19,\n",
              "        64, 44, 64, 81, 62, 81, 65, 21,  6, 42, 12, 22, 31, 17, 44, 11, 69,\n",
              "        50, 63, 17, 82, 15, 46, 66, 59, 86, 81, 78, 30,  8, 20, 52]),\n",
              " array([25, 22,  4,  4, 32, 14, 78, 63, 56, 63, 79,  3, 36, 92, 20, 79, 43,\n",
              "        41, 31, 37, 22, 41, 29, 88, 52, 82, 13, 80, 27, 41, 55, 26, 66, 60,\n",
              "        73, 45, 75, 45, 46, 30, 14, 94,  3, 24,  3, 18, 30, 57, 41]),\n",
              " array([21, 10, 51, 24, 19, 77, 26, 55, 33, 59, 11, 69, 15, 62, 18, 42, 40,\n",
              "        47,  0, 61, 82, 24,  4, 61, 56, 72, 57, 49, 79, 71, 57,  2, 24, 95,\n",
              "        34, 69,  2, 38, 61, 44,  9, 41,  5, 89, 92,  5,  5, 37, 25]),\n",
              " array([37,  8, 29,  0, 23, 38, 53,  6, 36, 27, 49, 16,  8,  4, 39, 90, 20,\n",
              "        15, 52, 18, 29, 80, 51, 60, 75, 92, 38, 93, 82, 18, 34, 46, 91, 15,\n",
              "        20, 25, 63, 27, 74, 35, 84, 57, 33, 67, 45, 11, 15, 39,  9]),\n",
              " array([81, 82, 62, 92, 25, 58, 36, 66, 29, 93, 84, 72, 42, 42, 83, 71, 80,\n",
              "        59,  0, 48, 25,  0, 16, 19, 29, 46, 82, 70, 23, 13, 90, 10, 95,  3,\n",
              "        89, 73, 42, 44, 68, 36, 72, 14, 39, 36, 19, 53, 63, 94, 41]),\n",
              " array([61, 70, 25,  0, 20, 49, 55, 80, 40, 72, 80, 16, 61, 55, 80, 51, 30,\n",
              "        76, 53, 65, 55,  4, 26, 70, 93,  9, 25, 71, 31, 16, 14, 24, 89, 46,\n",
              "        74,  1, 74, 68, 78,  9, 83, 79, 88, 56, 34, 77, 24, 86,  3]),\n",
              " array([62, 78, 77, 76, 23, 37, 29, 94, 58,  2, 13, 40, 34, 87, 31, 22, 72,\n",
              "        30, 64, 73, 83, 85, 51, 46, 62, 40,  9, 66, 89, 13,  6, 70, 52, 45,\n",
              "        79,  3, 89, 45, 78, 13,  3,  2, 65, 50, 70, 84, 10, 57, 93]),\n",
              " array([91, 22, 23, 37, 34, 91,  4, 15, 69, 22, 90, 55,  3, 48, 10, 15, 53,\n",
              "         1, 81, 18,  6,  1,  7, 82, 32, 87, 44, 44, 81, 77, 71, 69, 91, 41,\n",
              "        93, 67, 85, 38, 72, 81, 51, 69, 15, 65, 52, 85, 23, 63, 28]),\n",
              " array([56, 15,  2, 26, 77, 44, 89, 74, 24, 12, 19, 57, 14, 91,  0, 70, 95,\n",
              "        17, 12, 93, 54, 79, 46, 90, 11, 90, 52, 92, 36, 53, 48,  3, 95, 38,\n",
              "        79, 60, 16,  6,  9, 48, 83, 67, 85, 70, 56, 26, 35, 21, 37]),\n",
              " array([69, 71, 33, 25, 66, 41, 21, 65, 33, 48, 65, 22, 51, 64, 79,  7, 70,\n",
              "        85, 70, 42, 42, 35, 48,  6, 18,  7, 67, 74, 52, 15, 67, 78,  7, 54,\n",
              "        65, 59, 67, 69, 11, 11, 54, 35, 92, 83, 88,  9, 40, 33, 22]),\n",
              " array([16, 87, 55, 33, 73,  9,  8, 56, 56, 50, 91, 41,  9, 79, 45, 58,  3,\n",
              "        42, 33,  4, 12, 56, 68, 61, 17, 21, 11, 10, 38, 12, 48, 53,  6, 92,\n",
              "        89, 84, 13, 52, 94, 66, 32, 61, 83,  7, 51, 84, 33, 40, 50]),\n",
              " array([23, 92, 49, 16, 69, 43, 26, 70, 48, 41, 90, 59, 79, 71, 79, 19, 47,\n",
              "         9,  9, 93, 82, 19, 29, 17, 28, 25, 35, 84,  2,  8, 69, 16, 16, 16,\n",
              "        20, 17, 19, 58, 83,  0, 52, 39, 25, 54, 14, 80, 92, 14, 17]),\n",
              " array([57, 77, 63, 14, 54, 63, 42, 76, 45, 88, 25, 41, 93,  9, 40, 30,  4,\n",
              "        43, 51, 42, 47, 59, 50, 79, 26, 26, 75, 54, 31,  6, 67, 12, 79,  5,\n",
              "        17, 30, 70, 28, 28, 89, 50, 34, 72, 65, 54, 58,  6, 70, 77]),\n",
              " array([ 8, 86, 58, 88, 32, 21, 84, 60,  8, 53, 38,  8, 89, 23, 70, 42, 73,\n",
              "        80,  8, 76, 94, 10, 37, 32, 26, 78, 11, 82, 52, 54, 33, 11, 24, 48,\n",
              "         4, 52, 36, 63, 72, 82, 84, 49, 14, 92, 55, 68, 33, 79, 17]),\n",
              " array([58, 86,  8, 33, 75, 29, 19, 79, 51, 80, 87, 85, 92, 63, 13, 73, 37,\n",
              "        46, 51, 14, 10, 29, 70, 18, 21,  6, 13, 41, 65, 11, 17, 16, 70, 92,\n",
              "        66, 26, 16,  8, 54, 70, 26,  9,  3, 15, 94, 63, 14, 75, 16]),\n",
              " array([64, 86, 85,  1,  4,  0, 17, 85, 76, 12, 56, 70, 79, 71, 38, 60, 68,\n",
              "        82, 31, 25,  3, 28, 74, 72, 55, 51, 19, 48, 87, 46, 59, 58, 75, 51,\n",
              "        73,  7, 46, 21, 49, 71, 41, 15, 18, 48, 20, 39, 47, 48, 11]),\n",
              " array([62, 40, 49, 37, 49, 63, 61, 63, 45,  1, 44, 53, 53,  1, 86, 94,  6,\n",
              "        48, 85, 32, 43, 70, 34, 90, 60, 52, 61, 10, 32, 21, 31, 61, 19, 71,\n",
              "        79, 57, 15, 89, 40, 79, 85, 77,  4, 82, 59, 45, 14, 54, 64]),\n",
              " array([32, 78, 13, 57, 48, 11, 42, 51,  0, 12, 58, 42, 32, 23,  4, 66, 64,\n",
              "        24,  1, 72, 27, 86, 89, 15, 47, 18, 12, 65,  8, 42, 21, 58, 26,  4,\n",
              "        16,  8, 52,  9, 95, 82, 45, 47, 18, 40,  0, 12,  8, 32,  9]),\n",
              " array([69, 66, 59, 39, 72, 67, 42, 92, 18, 41, 19, 34, 70, 63, 51,  2, 40,\n",
              "        52, 92, 29, 95,  1, 74, 23,  0, 24, 51, 93,  6, 52,  7, 58,  3, 49,\n",
              "        93, 16, 71,  8, 12,  2, 14, 53, 95, 83, 73, 59, 67, 44, 64]),\n",
              " array([12, 51, 35, 48, 67, 30, 17, 63, 47, 53, 42, 49,  1,  6, 80, 58, 86,\n",
              "        54, 40, 22, 65, 36, 54,  6, 28, 47, 54, 63, 64, 41,  3, 80, 66, 33,\n",
              "        71, 75, 31,  0, 50, 29, 57, 46, 28, 25, 41, 40,  9, 30, 22]),\n",
              " array([33, 78, 57, 18, 28, 65, 72, 29, 65, 26, 25, 27, 12,  8, 57, 15, 17,\n",
              "        36, 52, 45,  3, 24, 83, 87, 23, 35, 15, 41, 77, 55, 85, 45, 45, 75,\n",
              "        40, 59, 77, 30, 21, 87, 76, 62, 47,  2, 83, 57,  9, 51, 53]),\n",
              " array([95, 14,  7, 20, 90, 66,  9, 33, 21,  9, 69, 65, 42, 22, 91, 24, 79,\n",
              "        80, 68, 15,  0, 17, 82, 18, 93, 40,  0, 17, 60, 67, 17, 87, 66,  8,\n",
              "        78, 61, 64, 37, 32, 66,  3, 44, 62,  8,  8, 82, 48, 45, 26]),\n",
              " array([93, 53, 24, 53, 74, 30, 92, 92, 47, 87, 56, 82,  7,  9, 13, 91,  0,\n",
              "        83, 86, 64, 11, 15, 86, 91, 71, 45, 86, 12, 61, 10, 25, 47, 80, 82,\n",
              "        78,  2,  4, 47,  2, 27, 21, 85, 51, 89, 35, 47, 69,  0, 35]),\n",
              " array([75,  6, 53, 14, 92, 15, 74, 67, 79, 73, 55, 74, 61, 25, 89, 35, 95,\n",
              "        76, 47, 88, 64, 16, 46,  8, 87, 82, 23, 30, 14,  8, 11,  9, 50, 51,\n",
              "        19, 95, 72, 85, 21, 31, 80, 68, 23, 23, 80, 65, 21,  8, 95]),\n",
              " array([27, 89, 23,  0, 85, 28, 93, 40, 43, 52, 39, 81, 75, 87, 90, 27,  4,\n",
              "        32, 64,  2, 36, 89, 79, 41, 88, 54, 47, 87, 40,  4, 86, 85, 32, 68,\n",
              "        83, 67, 17, 64, 74, 80,  4, 19, 69, 30, 25, 12, 64, 81, 83]),\n",
              " array([88,  2,  4, 29,  7, 81, 93,  1, 94, 62, 89, 72, 40, 30, 94, 94, 13,\n",
              "        63, 65, 17, 24, 87, 23,  1, 94, 89,  2,  6, 12,  7, 77, 76, 77, 80,\n",
              "        20, 79, 53, 52, 29, 74, 43, 37, 14, 35,  0, 60, 11, 84,  8]),\n",
              " array([71, 50, 94, 16, 30, 14, 42, 18, 83, 54, 60, 19, 54, 53,  8, 84,  3,\n",
              "        22, 83, 43, 14, 82, 59,  0, 80, 48, 80, 26, 61, 61, 60, 59, 67, 23,\n",
              "         9, 54, 38, 49, 95, 36, 79, 66, 47, 28, 92, 26,  5, 68, 64]),\n",
              " array([33, 21, 59, 40, 40,  5, 50, 94, 67, 20, 21, 34, 69, 31, 43, 14,  9,\n",
              "        14, 74, 72, 34, 38, 10, 91, 12, 95, 30, 18, 28, 92, 77, 57, 75, 89,\n",
              "        93, 51, 35, 41, 42, 77, 57, 72, 35,  9, 15, 86,  5, 72,  1]),\n",
              " array([48,  6, 56, 23, 17, 73, 43, 78, 43,  5, 93, 10, 20, 27, 27, 51, 67,\n",
              "        93, 66, 31, 67, 21, 15,  5, 23, 43, 26, 95, 54, 16, 50, 55, 92,  9,\n",
              "        78,  5, 76, 35, 78, 17, 37, 59, 49, 74, 19,  8, 43, 44, 43])]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.sequences_to_texts([tf.squeeze(tf.random.categorical(pred, num_samples=1), axis=-1).numpy() for pred in example_batch_predictions] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmWRrYq7VKjn",
        "outputId": "24814315-1ad9-44dd-e9c8-6e8e2ddf0267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['R Z O 5 e L `   1 | R Y T m Z \" j z L ! Q r ] S * Y b a 6 I v = g F   9 Y . L y I { 4 k R / { o =',\n",
              " 'P ^ F l 5 Q l ( ( . } G H Y ^ W 8 B 5 Y 8 f % X a U q a m | K 7 l a = l e { e % F h } j * 9 C f 5',\n",
              " 'D M c s g 1 ) p y i c = ^ 3 U - . D } \" E r a _ # D a H [ < ; O K b { ` Z V [ k m k S 1 ` U 1 D',\n",
              " \"k 0 O [ = u n : P * H R v J M q | 4 = S u z   z m [ 3 / F n % c ' F Y 4 \\\\ P 9 ( 6 - w 8 9 Z 7 E %\",\n",
              " 'a k K R _ N C C # A w ( b ^ s Q ! l R i Z W I 5 8 J ^ y : \\\\ v r d t ? C y u ~ / P q y w % } I | P',\n",
              " \"c f \\\\ F / : W S | | -   e \\\\ } 6 Q l Y { M d K C Z f Y * f + Q w z & I V v ) 8 d > H * i ' w j | ,\",\n",
              " '\\' 4 m E G G d ; U @ ^ A 3 s ` B \" * B y = m j ^ f K j . ] @ n ] r e { u : { ^ > 9 W = $ $ 5 f ]',\n",
              " '] $ & ^ c w ` j & o l U ^ u M   / K < } 8 G ^ f R a - z H d ~ d r N [ q # > C + Z F 7 9 n \" O r w',\n",
              " \"- d | Q U [ z ( o z ' ) l ( ~ A d & O ` R F t ' [ | @ s 9 w $ x p A L w 7 ) | n ] Z C ) 7 p   >\",\n",
              " 'c Y E * k $ W | ; R q r ( N # z q P [ = Q S ` s P x i C ] y 2 9 / %   p C Q f _ o O w V 0 P Q y',\n",
              " \"k n ~ 6 p X t F > ' H n Y ' $ L G M m &   t F + : ` p / V P f t u ] g S y o o 5 I U p z ` W\",\n",
              " 'U * - t Y = [ { \" ] s P q & ` 8 9 ; E W } i ~ 2 : k t 8 < e 0 Z l 6 _ T + v v l p Y % 1 - j Y } ^',\n",
              " '5 Z x a   j # @ % - N p = t w * ] 0 Y W x : ? f u ~ < Q , < 9 + Q 0 % 3 R V u p O A N > k F H V',\n",
              " \"# @ 3 * 2 + N K G 0 r ? ) r } w 6 = | r V o Y J V : T m Y F | } } ` ' G b | M t + n @ / A a } P\",\n",
              " 'M i # j N & B e l U { c f > . Q ? ( + 9 2 q 3 & * ) 8 D N F c | _ 1 I ? ] j ( D 9 b J > % o i ;',\n",
              " '! e t { ` D @ k J / a m j = r s | C D F d \" v E < 4 m : h s a J E d ) s @   0 W : 0 G Y t K \" t z',\n",
              " ': 0 % ( C j n 3 u N ` # 5 k m 5 K ? k c e ` y } )   R X : X n , A e n ! ( h S V l F h r o J v ) d',\n",
              " 'H W n i : A O E $ M I s r h w G 1 W o ( O 3 8 S O Y + h 3 Q + I F : - ; i m q j | [ g W ! d L q *',\n",
              " 'a { % @ Q w 1 e = 6 q @ % , { ~ Y r % - 2 = U < $ L Y n G C h . v 8 Y 4 C 9 E a / r ~ % 6 ^ 1 2',\n",
              " ': D z B # O b Z z m M ~ b i @ S C S   j . \" B d ( j _ \" \\\\ O 8 L \" n M   t a n m o ] | b y 1 U U $',\n",
              " \"P 3 J 3 S ' 6 l C o n i D O N _ y J c > - $ y 7 - S C P x 0 q n P M 1 _ [ M h V K t ' C W } ? d \\\\\",\n",
              " '_ \" F | C y B j 8 2 N = ) g V 7 ) ] L P \\' 5 C ~ X N _ h * . n 8 - | V l 2 % Y $ T q # g T S \\' / 7',\n",
              " 'y H p ; P Z R r { 3 0 Q \\' s % & i Z b k > k i o w i * K = \" A p > G a l ` [ > ` m \\' f S 4 v , B ]',\n",
              " 'd c p 0 l L 5 > Z * & } ~ X I % A . K K { c k U Y B c ?   z ? P a x u # ^ B D   9 e n ? > N - Z \\\\',\n",
              " \"B 6 ! { 9 P < R @ v ' o q < a } & ' V N 5 ? ] ? ) M , c * R 9 1 G Y   : 5 o 5 : V * n 0 Z S a L :\",\n",
              " 'm s A m 6 , e n 5 S l K \\\\ ; ? 4 I ` p \\\\ ~ ^ F < M - p + e X $ T c r 0 F y s V n 7 8 ] 0 _ D F h >',\n",
              " \"6 ` x ? Q 5 b L a y 8 7 S , \\\\ / % ) . I X - S 9 T y 7 : r W s ' K x $ O   @ ^ Y J b @ o M 6 r ^\",\n",
              " \"t [ k [ m q l _ D % + ' F 1 a $ q P h ~ r n p > . % z p 4 M [ @ : - : v # c i + ( s ~ u ? j : P\",\n",
              " 'L l B , a t h U / y R $ d U v > K A e !   e < m \" z - % Y # { D 6 9 0 v * [ 5 V 8 y f R 8 j k 6',\n",
              " \"F G 1   P b ; 1 U | b J w f i ] , D d ? 0 p & s l X 8 E Z ^ 8 ' * C i O @ G a Y A , c > % ' 6 e z\",\n",
              " '6 ] C \" W % q q z \\\\ T ! f ` M X 0 R + H w 3 f g ^ - c @ _ y j 5 = 2 L w _ y R \\\\ y o > T 5 u W Z c',\n",
              " 'K v } M 0 v E 4 p Q R @ y s c F H H d N # m T F k Y r F 0 K p s ] c y ) b ^ + w , W x L b U 0']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjdXFZeEBMBE",
        "outputId": "1fd2e9c5-e5db-46a8-99b0-5bd0013686d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 9, 33, 30, 90, 21, 58, 47, 20, 63, 26,  1,  1,  7, 25, 87, 38, 73,\n",
              "       91, 10, 40, 65, 62, 94, 88,  5, 45,  2,  0, 22, 92, 89, 69, 31, 75,\n",
              "       27,  9, 73, 23, 85, 93, 41, 42, 86,  7, 91, 46,  8, 64, 94])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnG1mnYvB0qr",
        "outputId": "43d1ccbd-8422-4713-d29b-5cf76d4448c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6, 31, 10,  5,  9, 15, 16,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "input_example_batch[0].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7codmZvjBN7w",
        "outputId": "19dffbfb-c045-4895-ee9c-99ced8f74d91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: ['2flirt4']\n",
            "next char prediction : ['rwj`cJDm*baaoy[I,\"lRW@}:iTed>^#f&kr,u<{SL~o\"CnV}']\n"
          ]
        }
      ],
      "source": [
        "print(f\"Input: {[''.join(i.split()) for i in tokenizer.sequences_to_texts([input_example_batch[0].numpy()]) ]}\")\n",
        "print(f\"next char prediction : {[''.join(i.split()) for i in tokenizer.sequences_to_texts([sampled_indices]) ]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBALEftdC0bn"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbTRPLyqBTjk"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da_L1HVxC9Lj",
        "outputId": "3f5b3106-ff48-4201-9e6b-c8344fde006b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (32, 49, 96)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.5686297, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFbMFwEmDA9D",
        "outputId": "ae8f3f65-b789-427e-baac-0cbf9c96b482"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96.41191"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_example_batch.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KS8fgGLRLcn",
        "outputId": "f7ddcfa5-04aa-4e7a-d7b8-2d08d79a98b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6, 31, 10, ...,  0,  0,  0],\n",
              "       [ 3, 14,  4, ...,  0,  0,  0],\n",
              "       [15, 23,  9, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [ 6,  6, 14, ...,  0,  0,  0],\n",
              "       [10,  7,  5, ...,  0,  0,  0],\n",
              "       [26, 23,  9, ...,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.sequences_to_texts(input_example_batch.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMMPSVNyRFSZ",
        "outputId": "cfbb658e-16d0-43f7-f57e-5f48dde5331f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2 f l i r t 4',\n",
              " '1 8 0 7 9 2',\n",
              " 't u r c a 1 0 3 8',\n",
              " 't o o l f a n 7',\n",
              " '3 3 4 4 2 8',\n",
              " 'm o m o g',\n",
              " 'g e n g u',\n",
              " 'i n s t p o i l 7',\n",
              " 't u n g g',\n",
              " '6 9 3 7 8 6 3',\n",
              " 'w e r o 8 4 8',\n",
              " 'k a s e y e v e r h a',\n",
              " 'o t t a n t u n',\n",
              " '0 9 4 0 0 1 6 9',\n",
              " 'f u c k a z 1',\n",
              " '7 6 9 5 9',\n",
              " 'a m y r i s n e',\n",
              " 'k e l l i e j a n',\n",
              " 'k u z a i m a',\n",
              " 'w h 6 3 9 6 3',\n",
              " 's c 2 5 2',\n",
              " 'n o n a 9',\n",
              " 'a s w 2 0 0',\n",
              " 'm a x k y k',\n",
              " 'R U B Y R I V E',\n",
              " 'j e r e s c',\n",
              " 'a m a t e r',\n",
              " 's a p h a r i 1',\n",
              " 'q w e r 1 3 5 7',\n",
              " '2 2 8 9 2 7 3',\n",
              " 'l o i u',\n",
              " 'b u r a k']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[p.split() for p in tokenizer.sequences_to_texts(input_example_batch.numpy())]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw_wqSU7z0io",
        "outputId": "0d9d640a-981b-4259-9d72-a97e869887b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['2', 'f', 'l', 'i', 'r', 't', '4'],\n",
              " ['1', '8', '0', '7', '9', '2'],\n",
              " ['t', 'u', 'r', 'c', 'a', '1', '0', '3', '8'],\n",
              " ['t', 'o', 'o', 'l', 'f', 'a', 'n', '7'],\n",
              " ['3', '3', '4', '4', '2', '8'],\n",
              " ['m', 'o', 'm', 'o', 'g'],\n",
              " ['g', 'e', 'n', 'g', 'u'],\n",
              " ['i', 'n', 's', 't', 'p', 'o', 'i', 'l', '7'],\n",
              " ['t', 'u', 'n', 'g', 'g'],\n",
              " ['6', '9', '3', '7', '8', '6', '3'],\n",
              " ['w', 'e', 'r', 'o', '8', '4', '8'],\n",
              " ['k', 'a', 's', 'e', 'y', 'e', 'v', 'e', 'r', 'h', 'a'],\n",
              " ['o', 't', 't', 'a', 'n', 't', 'u', 'n'],\n",
              " ['0', '9', '4', '0', '0', '1', '6', '9'],\n",
              " ['f', 'u', 'c', 'k', 'a', 'z', '1'],\n",
              " ['7', '6', '9', '5', '9'],\n",
              " ['a', 'm', 'y', 'r', 'i', 's', 'n', 'e'],\n",
              " ['k', 'e', 'l', 'l', 'i', 'e', 'j', 'a', 'n'],\n",
              " ['k', 'u', 'z', 'a', 'i', 'm', 'a'],\n",
              " ['w', 'h', '6', '3', '9', '6', '3'],\n",
              " ['s', 'c', '2', '5', '2'],\n",
              " ['n', 'o', 'n', 'a', '9'],\n",
              " ['a', 's', 'w', '2', '0', '0'],\n",
              " ['m', 'a', 'x', 'k', 'y', 'k'],\n",
              " ['R', 'U', 'B', 'Y', 'R', 'I', 'V', 'E'],\n",
              " ['j', 'e', 'r', 'e', 's', 'c'],\n",
              " ['a', 'm', 'a', 't', 'e', 'r'],\n",
              " ['s', 'a', 'p', 'h', 'a', 'r', 'i', '1'],\n",
              " ['q', 'w', 'e', 'r', '1', '3', '5', '7'],\n",
              " ['2', '2', '8', '9', '2', '7', '3'],\n",
              " ['l', 'o', 'i', 'u'],\n",
              " ['b', 'u', 'r', 'a', 'k']]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "[re.findall('..?',\"\".join(p.split())) for p in tokenizer.sequences_to_texts(input_example_batch.numpy())]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST9BOPSHVpMI",
        "outputId": "93db62fb-77f4-4912-d83c-daf61625367a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['2f', 'li', 'rt', '4'],\n",
              " ['18', '07', '92'],\n",
              " ['tu', 'rc', 'a1', '03', '8'],\n",
              " ['to', 'ol', 'fa', 'n7'],\n",
              " ['33', '44', '28'],\n",
              " ['mo', 'mo', 'g'],\n",
              " ['ge', 'ng', 'u'],\n",
              " ['in', 'st', 'po', 'il', '7'],\n",
              " ['tu', 'ng', 'g'],\n",
              " ['69', '37', '86', '3'],\n",
              " ['we', 'ro', '84', '8'],\n",
              " ['ka', 'se', 'ye', 've', 'rh', 'a'],\n",
              " ['ot', 'ta', 'nt', 'un'],\n",
              " ['09', '40', '01', '69'],\n",
              " ['fu', 'ck', 'az', '1'],\n",
              " ['76', '95', '9'],\n",
              " ['am', 'yr', 'is', 'ne'],\n",
              " ['ke', 'll', 'ie', 'ja', 'n'],\n",
              " ['ku', 'za', 'im', 'a'],\n",
              " ['wh', '63', '96', '3'],\n",
              " ['sc', '25', '2'],\n",
              " ['no', 'na', '9'],\n",
              " ['as', 'w2', '00'],\n",
              " ['ma', 'xk', 'yk'],\n",
              " ['RU', 'BY', 'RI', 'VE'],\n",
              " ['je', 're', 'sc'],\n",
              " ['am', 'at', 'er'],\n",
              " ['sa', 'ph', 'ar', 'i1'],\n",
              " ['qw', 'er', '13', '57'],\n",
              " ['22', '89', '27', '3'],\n",
              " ['lo', 'iu'],\n",
              " ['bu', 'ra', 'k']]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bleu_score(y_true, y_pred):\n",
        "  true_seq = tokenizer.sequences_to_texts(y_true.numpy())\n",
        "  reference = [p.split() if p.split() else [' '] for p in true_seq]\n",
        "  preds = [tf.squeeze(tf.random.categorical(pred, num_samples=1), axis=-1).numpy() for pred in y_pred]\n",
        "  hypothesis = [p.split() if p.split() else [' '] for p in tokenizer.sequences_to_texts(preds)]\n",
        "  return corpus_bleu(reference, hypothesis)"
      ],
      "metadata": {
        "id": "rrAPoMBNMSLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bleu_score_bi(y_true, y_pred):\n",
        "  true_seq = tokenizer.sequences_to_texts(y_true.numpy())\n",
        "  reference = [re.findall('..?',\"\".join(p.split())) if p.split() else [' '] for p in true_seq]\n",
        "  preds = [tf.squeeze(tf.random.categorical(pred, num_samples=1), axis=-1).numpy() for pred in y_pred]\n",
        "  hypothesis = [re.findall('..?',\"\".join(p.split())) if p.split() else [' '] for p in tokenizer.sequences_to_texts(preds)]\n",
        "  return corpus_bleu(reference, hypothesis)  "
      ],
      "metadata": {
        "id": "c6spfpFCYbyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_score(input_example_batch, example_batch_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqLk3Mf7N_I_",
        "outputId": "c79b7ec6-625a-4841-cc4e-cb3de35e31fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4722506447352589"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_score_bi(input_example_batch, example_batch_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYj4yDAxYrB7",
        "outputId": "c5b894dc-25d7-4ea2-f2b2-2330bd133fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18928475425929298"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.006)"
      ],
      "metadata": {
        "id": "Sws6TEcADaxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96AjYUtXDE_z"
      },
      "outputs": [],
      "source": [
        "# GPU\n",
        "model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONpAEo_pDJCI"
      },
      "source": [
        "# Configure Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeFYT7f0DHLB"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints_lstm'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "earlystopping_cb = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor = 'val_accuracy',\n",
        "    mode = 'max',\n",
        "    verbose = 1,\n",
        "    patience = 3,\n",
        "    restore_best_weights = True\n",
        ")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    monitor = 'val_accuracy',\n",
        "    mode = 'max',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True, \n",
        "    verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7bzPMbMDO6i",
        "outputId": "6e1a52d6-7955-4a89-bc85-45a2d7805816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "400498/400500 [============================>.] - ETA: 0s - loss: 0.4009 - accuracy: 0.8860\n",
            "Epoch 1: val_accuracy improved from -inf to 0.88523, saving model to ./training_checkpoints_lstm/ckpt_1\n",
            "400500/400500 [==============================] - 9626s 24ms/step - loss: 0.4009 - accuracy: 0.8860 - val_loss: 0.3939 - val_accuracy: 0.8852\n",
            "Epoch 2/20\n",
            "400500/400500 [==============================] - ETA: 0s - loss: 0.3923 - accuracy: 0.8884\n",
            "Epoch 2: val_accuracy improved from 0.88523 to 0.88582, saving model to ./training_checkpoints_lstm/ckpt_2\n",
            "400500/400500 [==============================] - 9532s 24ms/step - loss: 0.3923 - accuracy: 0.8884 - val_loss: 0.3920 - val_accuracy: 0.8858\n",
            "Epoch 3/20\n",
            "400500/400500 [==============================] - ETA: 0s - loss: 0.3895 - accuracy: 0.8892\n",
            "Epoch 3: val_accuracy improved from 0.88582 to 0.88616, saving model to ./training_checkpoints_lstm/ckpt_3\n",
            "400500/400500 [==============================] - 9550s 24ms/step - loss: 0.3895 - accuracy: 0.8892 - val_loss: 0.3909 - val_accuracy: 0.8862\n",
            "Epoch 4/20\n",
            "400498/400500 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8895\n",
            "Epoch 4: val_accuracy improved from 0.88616 to 0.88639, saving model to ./training_checkpoints_lstm/ckpt_4\n",
            "400500/400500 [==============================] - 9537s 24ms/step - loss: 0.3886 - accuracy: 0.8895 - val_loss: 0.3902 - val_accuracy: 0.8864\n",
            "Epoch 5/20\n",
            "400499/400500 [============================>.] - ETA: 0s - loss: 0.4274 - accuracy: 0.8827\n",
            "Epoch 5: val_accuracy did not improve from 0.88639\n",
            "400500/400500 [==============================] - 9526s 24ms/step - loss: 0.4274 - accuracy: 0.8827 - val_loss: 0.5243 - val_accuracy: 0.8652\n",
            "Epoch 6/20\n",
            "400500/400500 [==============================] - ETA: 0s - loss: 0.5010 - accuracy: 0.8673\n",
            "Epoch 6: val_accuracy did not improve from 0.88639\n",
            "400500/400500 [==============================] - 9557s 24ms/step - loss: 0.5010 - accuracy: 0.8673 - val_loss: 0.4934 - val_accuracy: 0.8651\n",
            "Epoch 7/20\n",
            "400498/400500 [============================>.] - ETA: 0s - loss: 0.4870 - accuracy: 0.8678\n",
            "Epoch 7: val_accuracy did not improve from 0.88639\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "400500/400500 [==============================] - 9574s 24ms/step - loss: 0.4870 - accuracy: 0.8678 - val_loss: 0.4836 - val_accuracy: 0.8662\n",
            "Epoch 7: early stopping\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "history = model.fit(train_dataset, \n",
        "                    validation_data=val_dataset,\n",
        "                    epochs=EPOCHS, \n",
        "                    callbacks=[checkpoint_callback, earlystopping_cb])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('saved_model/password')"
      ],
      "metadata": {
        "id": "fDvYsm263fJg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c7ad5d-c26c-4272-d85e-7ff64e553daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/password/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/password/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3472dd2610> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('saved_model/password')"
      ],
      "metadata": {
        "id": "oEiwV9IuFES6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyaIGJ02FSUw",
        "outputId": "a42ab5d8-8457-4a33-ef08-d715d755b5fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    multiple                  9216      \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               multiple                  17571840  \n",
            "                                                                 \n",
            " dense_9 (Dense)             multiple                  196704    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,777,760\n",
            "Trainable params: 17,777,760\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot"
      ],
      "metadata": {
        "id": "vILPfriJ3u0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "history_dict.keys()\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "hTrm3PU1Na3d",
        "outputId": "8ac7960e-e222-4906-93d1-a1829ae05191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "dbx5k9cC39RN",
        "outputId": "477af712-8882-4dbf-80d3-41b0fc5b432a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BLEU score on test dataset"
      ],
      "metadata": {
        "id": "RdQNvSLnM5S2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try model without training\n",
        "scores = []\n",
        "for input_test_batch, target_test_batch in test_dataset:\n",
        "    test_batch_predictions = model(input_test_batch)\n",
        "    scores.append(bleu_score(target_test_batch, test_batch_predictions))"
      ],
      "metadata": {
        "id": "XUhbQg9mISjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b056188-d077-4170-8a3f-9c5abc0d7b39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(scores)/len(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYjHakavNCwz",
        "outputId": "e4f1ada7-a8d0-4975-b801-d997483c9a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7573974452896757"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try model without training\n",
        "scores = []\n",
        "for input_test_batch, target_test_batch in test_dataset:\n",
        "    test_batch_predictions = model(input_test_batch)\n",
        "    scores.append(bleu_score_bi(target_test_batch, test_batch_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eINGcfO0Yw9_",
        "outputId": "e16d171e-b94c-49f6-e054-f42e618c034d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(scores)/len(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BW_D1x8Y2Em",
        "outputId": "c7721f3d-58fa-4a93-e601-aecddca4133c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.48197460643243134"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "LATLVobwGxLm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0Qx47m_DrER"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, tokenizer, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  #@tf.function\n",
        "  def generate_one_step(self, input_chars, states=None):\n",
        "    #import pdb; pdb.set_trace()\n",
        "    # Convert strings to token IDs.\n",
        "    # input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.tokenizer.texts_to_sequences(input_chars)\n",
        "    input_ids = tf.keras.preprocessing.sequence.pad_sequences(input_ids, padding='post')\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states_h, states_c = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.tokenizer.sequences_to_texts([predicted_ids.numpy()])\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, [states_h, states_c]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model, tokenizer)"
      ],
      "metadata": {
        "id": "LKowDQATBC7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = ['w']\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(2):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HFmNMULBFiT",
        "outputId": "37e30614-d0ee-419d-dec7-18c1c72f8a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wed \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 0.016946792602539062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pwds_from_chars(start_char, len):\n",
        "  states = None\n",
        "  next_char = [start_char]\n",
        "  result = [next_char]\n",
        "\n",
        "  for n in range(len-1):\n",
        "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "    result.append(next_char)\n",
        "\n",
        "  result = tf.strings.join(result)\n",
        "  return result[0].numpy().decode('utf-8')"
      ],
      "metadata": {
        "id": "bjhAj-YzcxvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_pos = []\n",
        "while True:\n",
        "  pred = pwds_from_chars('p', 4)\n",
        "  if pred not in all_pos:\n",
        "    all_pos.append(pred)\n",
        "  else:\n",
        "    break\n",
        "\n",
        "print(all_pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUZqumbSdIKx",
        "outputId": "d8e83289-6aea-491b-d9c8-f742f5eb487d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['paka', 'pplp', 'pook', 'pusa', 'p1x6', 'pari', 'prop', 'payt', 'palo', 'psr0', 'plea', 'peps', 'pedr', 'phat', 'pimy', 'puma', 'pe5a', 'pupp', 'play', 'pakd', 'prin', 'plut', 'pela', 'patr']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "given_pass = 'Password1'\n",
        "attempts = 1\n",
        "\n",
        "while True:\n",
        "  pred = pwds_from_chars(given_pass[0], len(given_pass))\n",
        "  print(f\"{attempts} - {pred}\")\n",
        "  if pred == given_pass:\n",
        "    break\n",
        "  attempts += 1\n",
        "\n",
        "print(f\"Model took {attempts} attempts to find password - {given_pass}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_Z66oP2d-zL",
        "outputId": "5a870829-9e3c-4fca-e944-66b432f4bead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 - Perno1259\n",
            "2 - Purice098\n",
            "3 - Patience4\n",
            "4 - PJABCrew3\n",
            "5 - Portdolpi\n",
            "6 - PraiseHop\n",
            "7 - PictureWi\n",
            "8 - P98041065\n",
            "9 - PISCISTO0\n",
            "10 - Passer469\n",
            "11 - Proxlucks\n",
            "12 - PopyNikes\n",
            "13 - PANDA69CH\n",
            "14 - Perry0606\n",
            "15 - PeggyWigg\n",
            "16 - Pnel08059\n",
            "17 - PJ12jqks6\n",
            "18 - Patsymon1\n",
            "19 - PLAYBOY22\n",
            "20 - PxZgtnzQ3\n",
            "21 - PregleLan\n",
            "22 - Pointon72\n",
            "23 - PE4CESEXY\n",
            "24 - POP214810\n",
            "25 - PECOASTIO\n",
            "26 - PROSPECTS\n",
            "27 - PHONEspoo\n",
            "28 - PXNDX8285\n",
            "29 - PLK9999II\n",
            "30 - PRINCE060\n",
            "31 - P@nt15tv1\n",
            "32 - Pfairview\n",
            "33 - PALMEROAD\n",
            "34 - PAO714518\n",
            "35 - PATMC2815\n",
            "36 - Pknhkl151\n",
            "37 - PARLA9357\n",
            "38 - P1d1aCK19\n",
            "39 - Policia07\n",
            "40 - PERFECT51\n",
            "41 - PINKCHOPP\n",
            "42 - Porkidoho\n",
            "43 - Paulamarc\n",
            "44 - P1m1n43v3\n",
            "45 - PAUL08240\n",
            "46 - Pineapple\n",
            "47 - PAUL2004S\n",
            "48 - PLUS12121\n",
            "49 - PANERA123\n",
            "50 - Pa1577971\n",
            "51 - Pachola27\n",
            "52 - Piochenta\n",
            "53 - PREDESTIN\n",
            "54 - Pussy2065\n",
            "55 - Paje19802\n",
            "56 - Potokal60\n",
            "57 - PLAYBOIBO\n",
            "58 - Penuta198\n",
            "59 - PEDROFF10\n",
            "60 - POUSSTIK5\n",
            "61 - PRILLURE3\n",
            "62 - POWEA69CH\n",
            "63 - Pink424sH\n",
            "64 - PbismisHe\n",
            "65 - PASSMORE1\n",
            "66 - PAINT3228\n",
            "67 - PANGA3651\n",
            "68 - Ph32Tnitc\n",
            "69 - Pengie915\n",
            "70 - PARTYGIRL\n",
            "71 - PESOJAS20\n",
            "72 - PrIsH1234\n",
            "73 - PJBARCELO\n",
            "74 - POFOX14NO\n",
            "75 - PI13UB13H\n",
            "76 - PKgt30-MK\n",
            "77 - PAUL06240\n",
            "78 - PrincessD\n",
            "79 - Parttyrul\n",
            "80 - PORTI1234\n",
            "81 - PLAYSTATI\n",
            "82 - Puke81281\n",
            "83 - PATHEY174\n",
            "84 - PIOLIN210\n",
            "85 - Password8\n",
            "86 - PETEECREW\n",
            "87 - Pallmallm\n",
            "88 - P0RK3ST0N\n",
            "89 - PLAYAALLD\n",
            "90 - Patamakes\n",
            "91 - PH0EN186*\n",
            "92 - Polita101\n",
            "93 - Pkin11831\n",
            "94 - PINK24752\n",
            "95 - PUPPYNACI\n",
            "96 - PETETK123\n",
            "97 - Preodarie\n",
            "98 - Pvnt_S_CA\n",
            "99 - PAMELAX10\n",
            "100 - PKWjess45\n",
            "101 - POOMIOMAX\n",
            "102 - Pepperpep\n",
            "103 - P9neCQdJh\n",
            "104 - PAZnivell\n",
            "105 - Pug220712\n",
            "106 - PuSeGo199\n",
            "107 - Poncaxpas\n",
            "108 - PEbbles00\n",
            "109 - PECHON200\n",
            "110 - PICOLA107\n",
            "111 - PBATURMAN\n",
            "112 - PDrogsw12\n",
            "113 - PEXPY7115\n",
            "114 - Pograhcf2\n",
            "115 - PELIGROSO\n",
            "116 - Pussycats\n",
            "117 - PS0808921\n",
            "118 - Pxl(L)(@)\n",
            "119 - PUERCOPIE\n",
            "120 - Pomarr132\n",
            "121 - Padilla22\n",
            "122 - PORCHATAT\n",
            "123 - Pepsi2310\n",
            "124 - PICIUS_sm\n",
            "125 - Piggy...X\n",
            "126 - POPCORN42\n",
            "127 - Poncho197\n",
            "128 - PRIZEBREE\n",
            "129 - Pamasvera\n",
            "130 - PRETTYTRE\n",
            "131 - PB030161Y\n",
            "132 - Pumpkin.b\n",
            "133 - PQ3E43535\n",
            "134 - Parias401\n",
            "135 - PIAED2017\n",
            "136 - P200704wa\n",
            "137 - P0LT20102\n",
            "138 - Promise12\n",
            "139 - PrinzesS_\n",
            "140 - PM41104HP\n",
            "141 - PkqRfmchi\n",
            "142 - P3z1beBOy\n",
            "143 - Provosk12\n",
            "144 - Peanut!13\n",
            "145 - Pakalocki\n",
            "146 - PATIANA12\n",
            "147 - PIMPIN103\n",
            "148 - Peggy6498\n",
            "149 - Pk4K058pP\n",
            "150 - Puseedher\n",
            "151 - PAT_EATER\n",
            "152 - Proudgirl\n",
            "153 - PonY&Giga\n",
            "154 - PUTOS...X\n",
            "155 - Pfluffy78\n",
            "156 - PRINCE292\n",
            "157 - Peewee200\n",
            "158 - PLAYBOYCH\n",
            "159 - P1lletZak\n",
            "160 - Partouill\n",
            "161 - PEPSIRULE\n",
            "162 - PASSWORD5\n",
            "163 - Plop991..\n",
            "164 - Pavel42-2\n",
            "165 - PENSINK09\n",
            "166 - PTc073410\n",
            "167 - PACO21908\n",
            "168 - PATNIOSSH\n",
            "169 - P1atpark1\n",
            "170 - Power1350\n",
            "171 - Patrika88\n",
            "172 - PHOENIX19\n",
            "173 - POESIES2P\n",
            "174 - Popwaters\n",
            "175 - PIMP11248\n",
            "176 - PMS111581\n",
            "177 - PIMPAGIRL\n",
            "178 - Protheo09\n",
            "179 - Prinalex0\n",
            "180 - PWINHESSH\n",
            "181 - PADILLAC2\n",
            "182 - Pz1CSVH35\n",
            "183 - PINKSTARD\n",
            "184 - PNINASAM1\n",
            "185 - PEPSIWARR\n",
            "186 - PABLO6679\n",
            "187 - Peloskiti\n",
            "188 - Petpie200\n",
            "189 - PrO5LJTy9\n",
            "190 - PaloM1497\n",
            "191 - PRINCESAB\n",
            "192 - Pineapple\n",
            "193 - Petra-Fix\n",
            "194 - Psico.150\n",
            "195 - Popatop9\\\n",
            "196 - PHILO9711\n",
            "197 - Pa4soor4u\n",
            "198 - PIOJOSA08\n",
            "199 - PRANAshty\n",
            "200 - P15449123\n",
            "201 - PassworD2\n",
            "202 - PB2327873\n",
            "203 - POWERFREE\n",
            "204 - Puma30058\n",
            "205 - PliBurE20\n",
            "206 - PCQ3Hmn5t\n",
            "207 - PICTURESA\n",
            "208 - PELIGROSA\n",
            "209 - Porlay990\n",
            "210 - Petty*162\n",
            "211 - PABLo9211\n",
            "212 - PaLlHroom\n",
            "213 - P001lmona\n",
            "214 - Pythfiles\n",
            "215 - PSpmCarp1\n",
            "216 - POOHIEPIE\n",
            "217 - PPFZ17565\n",
            "218 - Piparesa2\n",
            "219 - PH258AAA0\n",
            "220 - PEPPERDOG\n",
            "221 - PRR2G2821\n",
            "222 - POLANLOLE\n",
            "223 - PEDRO9568\n",
            "224 - PAULA1175\n",
            "225 - PRIYAONEN\n",
            "226 - PinkStar0\n",
            "227 - PAUVANATU\n",
            "228 - P2***-*45\n",
            "229 - Pessin901\n",
            "230 - Poolsucks\n",
            "231 - Pokemon'a\n",
            "232 - P4v4M3231\n",
            "233 - Paperdanc\n",
            "234 - PeaPle#45\n",
            "235 - PTDVALLEY\n",
            "236 - PERZIGTOR\n",
            "237 - PHYKONPIG\n",
            "238 - PlayaJen_\n",
            "239 - PIZZAROCK\n",
            "240 - P2MIKaTxc\n",
            "241 - Priyasorp\n",
            "242 - PEHD65886\n",
            "243 - PACKER449\n",
            "244 - POINTHOLE\n",
            "245 - PLOKIPEMK\n",
            "246 - PROFESSOR\n",
            "247 - Progressi\n",
            "248 - POWERPIVE\n",
            "249 - Putsuka_7\n",
            "250 - PINKY1588\n",
            "251 - Pepsis101\n",
            "252 - P31222221\n",
            "253 - P*L100DCP\n",
            "254 - Ploy25312\n",
            "255 - PATUSVAEG\n",
            "256 - POLKADOT?\n",
            "257 - PrettyGir\n",
            "258 - Partite12\n",
            "259 - Phrida040\n",
            "260 - PMIGREEN3\n",
            "261 - P07149377\n",
            "262 - PALAGAMIG\n",
            "263 - PatcelLa!\n",
            "264 - Poniesxx3\n",
            "265 - POLICIA25\n",
            "266 - P3r1kedaw\n",
            "267 - PupPy_078\n",
            "268 - POOHbear1\n",
            "269 - Pelusito0\n",
            "270 - PIE626MAN\n",
            "271 - PIphim019\n",
            "272 - Piglet_19\n",
            "273 - PRO556654\n",
            "274 - Pat071849\n",
            "275 - PANCHITA6\n",
            "276 - Princess1\n",
            "277 - Piobobel7\n",
            "278 - Poohbearb\n",
            "279 - PAULKIMTO\n",
            "280 - PUTA1010T\n",
            "281 - P6u9R5795\n",
            "282 - Pookeysoc\n",
            "283 - PRISTESIS\n",
            "284 - P12702109\n",
            "285 - Pink20090\n",
            "286 - Patriaika\n",
            "287 - Parnelle1\n",
            "288 - PONCIOLAT\n",
            "289 - PxNjxh3yX\n",
            "290 - PAUL121LA\n",
            "291 - PENNBELLS\n",
            "292 - PUNCATAMA\n",
            "293 - POIPOI777\n",
            "294 - PH5034577\n",
            "295 - PIJA22703\n",
            "296 - PUPUSKASI\n",
            "297 - PABLO8608\n",
            "298 - PaM4TerEi\n",
            "299 - Pukkatayd\n",
            "300 - PILARI201\n",
            "301 - Pudge0818\n",
            "302 - PHP&[IR,)\n",
            "303 - Patch0921\n",
            "304 - Peeps0420\n",
            "305 - Polkem2me\n",
            "306 - PATA@USA1\n",
            "307 - PRICETENS\n",
            "308 - PF1LAK3MO\n",
            "309 - Pamela38_\n",
            "310 - Pennywels\n",
            "311 - PWDOENEGH\n",
            "312 - Peoples12\n",
            "313 - PESTXNPUD\n",
            "314 - PERROSMIL\n",
            "315 - POWEROILS\n",
            "316 - Photogirl\n",
            "317 - PhRamBohc\n",
            "318 - PTS23cPs1\n",
            "319 - PEEWEE24G\n",
            "320 - PeePee332\n",
            "321 - PXNDX31JA\n",
            "322 - PINKHOPJA\n",
            "323 - Poopoo!!!\n",
            "324 - PSP529720\n",
            "325 - POOHBABE1\n",
            "326 - PEQUETEQU\n",
            "327 - PAINTIN48\n",
            "328 - PODGEMAIL\n",
            "329 - PinKie310\n",
            "330 - Pebbles82\n",
            "331 - PENSHIRE1\n",
            "332 - P12941ngZ\n",
            "333 - Pookpath1\n",
            "334 - Pamelarob\n",
            "335 - PAPELWEEN\n",
            "336 - PUAME0707\n",
            "337 - Pocadeta0\n",
            "338 - Petshow99\n",
            "339 - PRAPATAKI\n",
            "340 - PAOLA5577\n",
            "341 - PIPINchai\n",
            "342 - Polka2B8l\n",
            "343 - PdtpevN74\n",
            "344 - PASSWORDG\n",
            "345 - PASCHALAT\n",
            "346 - POHEREAMO\n",
            "347 - PPE341256\n",
            "348 - PESHMED11\n",
            "349 - POPISpoop\n",
            "350 - PICKLE999\n",
            "351 - Pudding17\n",
            "352 - Pynkatiut\n",
            "353 - PoP526818\n",
            "354 - PELONTINY\n",
            "355 - PEPERM193\n",
            "356 - PEUCEUSCA\n",
            "357 - PH0310979\n",
            "358 - PIRAT3S42\n",
            "359 - PAN196196\n",
            "360 - Pinkmoon1\n",
            "361 - PATTANA10\n",
            "362 - PLOP02896\n",
            "363 - PORTH99**\n",
            "364 - Polkadot5\n",
            "365 - Poldis890\n",
            "366 - Praha123k\n",
            "367 - PATH29432\n",
            "368 - PICHUD124\n",
            "369 - POPCORN45\n",
            "370 - PSrDM7741\n",
            "371 - Panosshir\n",
            "372 - PEACHES93\n",
            "373 - Popcorn12\n",
            "374 - Patricia9\n",
            "375 - Posrusagi\n",
            "376 - POINters1\n",
            "377 - PAMELA230\n",
            "378 - POPPDWARE\n",
            "379 - Plains1da\n",
            "380 - PALOSTQM1\n",
            "381 - Pam.22141\n",
            "382 - PICCOLEDA\n",
            "383 - Patty@200\n",
            "384 - Paper1@31\n",
            "385 - Perfect99\n",
            "386 - PEDIAVOLA\n",
            "387 - Pete06090\n",
            "388 - PURPLE123\n",
            "389 - Pastor12$\n",
            "390 - PETERJONE\n",
            "391 - Polli1964\n",
            "392 - PETTENEWI\n",
            "393 - PROTECE12\n",
            "394 - Pink19850\n",
            "395 - PROCEED36\n",
            "396 - Punish540\n",
            "397 - PpYGTgH44\n",
            "398 - P13J13H13\n",
            "399 - PBE29da56\n",
            "400 - PETIE1111\n",
            "401 - P2HZIn875\n",
            "402 - PRINCESS0\n",
            "403 - Paul46+@6\n",
            "404 - Pottell08\n",
            "405 - POCKE2318\n",
            "406 - Palkuicha\n",
            "407 - PeruGuhuu\n",
            "408 - PRUESTIGR\n",
            "409 - Pathtoren\n",
            "410 - POOTROOFL\n",
            "411 - Pollocosi\n",
            "412 - Petty77!!\n",
            "413 - Poomaas13\n",
            "414 - Princi250\n",
            "415 - PEAUTITIA\n",
            "416 - PIMP11142\n",
            "417 - PLOOF7741\n",
            "418 - Pastor445\n",
            "419 - Passwor21\n",
            "420 - Phylondan\n",
            "421 - PEG$34THO\n",
            "422 - Prispa061\n",
            "423 - PEI803340\n",
            "424 - PARONACE1\n",
            "425 - PLORRKE20\n",
            "426 - Piccolo_1\n",
            "427 - P796n6R9L\n",
            "428 - Peepie636\n",
            "429 - PENCELO54\n",
            "430 - PASTRULER\n",
            "431 - PIS2@1048\n",
            "432 - PQXZ100FE\n",
            "433 - PEEW69GRE\n",
            "434 - Pikechant\n",
            "435 - PERpenDTh\n",
            "436 - PhAnY8912\n",
            "437 - PEYAPRIME\n",
            "438 - PIPOLETTE\n",
            "439 - P2ppbBu76\n",
            "440 - PIOLINJR0\n",
            "441 - Pumpkin19\n",
            "442 - PGavin254\n",
            "443 - Panthers6\n",
            "444 - Play15122\n",
            "445 - Peece3693\n",
            "446 - PIM015203\n",
            "447 - POLHUGOUG\n",
            "448 - PucKers21\n",
            "449 - PHIP36104\n",
            "450 - Peppie345\n",
            "451 - Pepper101\n",
            "452 - PLABLOSTB\n",
            "453 - Podz11120\n",
            "454 - PORTA0353\n",
            "455 - PAYTON053\n",
            "456 - POTIK1524\n",
            "457 - PPUMAS190\n",
            "458 - PML2005kc\n",
            "459 - PIYESS123\n",
            "460 - PROJECT34\n",
            "461 - PINKYBOO1\n",
            "462 - Pass2theg\n",
            "463 - PAME26575\n",
            "464 - PEEMUNION\n",
            "465 - PARISTEVI\n",
            "466 - POLLO*231\n",
            "467 - Pass32+73\n",
            "468 - Pe1jan2b!\n",
            "469 - PINGRAY24\n",
            "470 - PryEtotte\n",
            "471 - P786AGCEV\n",
            "472 - POOHBEARS\n",
            "473 - PINGROBER\n",
            "474 - POBOX1695\n",
            "475 - Pratama11\n",
            "476 - PABLOGEMM\n",
            "477 - Peke13235\n",
            "478 - PLEBURSEN\n",
            "479 - PPs32)Kua\n",
            "480 - PUA260919\n",
            "481 - PUMAS1.1.\n",
            "482 - PKNUCH8B8\n",
            "483 - PASS330WO\n",
            "484 - PAraantip\n",
            "485 - PRISI1H78\n",
            "486 - PUSSY1980\n",
            "487 - Paparobbi\n",
            "488 - Pd16DI08j\n",
            "489 - PNPJEUDGA\n",
            "490 - Portland7\n",
            "491 - PATCH1010\n",
            "492 - Powelltop\n",
            "493 - PRILIA686\n",
            "494 - PMAMA-255\n",
            "495 - Pretty124\n",
            "496 - PRUE10050\n",
            "497 - PVISHAKON\n",
            "498 - Pv3MDQTUy\n",
            "499 - Pittbull6\n",
            "500 - PAPERPIES\n",
            "501 - PUXSCJO13\n",
            "502 - PUNK PICS\n",
            "503 - Paul33248\n",
            "504 - PMHS26674\n",
            "505 - PODAY9154\n",
            "506 - PURPLE123\n",
            "507 - PASAKUra0\n",
            "508 - Pampol123\n",
            "509 - Patito_25\n",
            "510 - PICHGO220\n",
            "511 - PLD090905\n",
            "512 - PIVOJOVID\n",
            "513 - Phoenix_3\n",
            "514 - Planet628\n",
            "515 - Pitzicapi\n",
            "516 - Poncho232\n",
            "517 - PEDELAMOR\n",
            "518 - Post pigs\n",
            "519 - P26037837\n",
            "520 - PESTANSCH\n",
            "521 - PatrickTi\n",
            "522 - PITA12345\n",
            "523 - POPE28GER\n",
            "524 - PLAY3RSIT\n",
            "525 - POLIKBAN1\n",
            "526 - PISATCHIN\n",
            "527 - PYMPSPA.S\n",
            "528 - Pt.#70*85\n",
            "529 - Pauliyah1\n",
            "530 - PIERINA09\n",
            "531 - PaKaX2asq\n",
            "532 - Phish1822\n",
            "533 - PE53WL317\n",
            "534 - PEDELETT5\n",
            "535 - PC7ERCA,7\n",
            "536 - PUCCAELI3\n",
            "537 - PAS082200\n",
            "538 - PATELMC22\n",
            "539 - Pi4G9Mic8\n",
            "540 - Proud#010\n",
            "541 - PefaAngIl\n",
            "542 - PERUM1234\n",
            "543 - Prakritt1\n",
            "544 - Pu1piru12\n",
            "545 - Planb2357\n",
            "546 - Papasito1\n",
            "547 - P@sTpK4Ap\n",
            "548 - PEpperjo2\n",
            "549 - Powerful7\n",
            "550 - PPX18USAC\n",
            "551 - P885803py\n",
            "552 - Pau354win\n",
            "553 - PYPRIOS39\n",
            "554 - Panthers8\n",
            "555 - PANEKANOS\n",
            "556 - Peewee123\n",
            "557 - POSITIVE0\n",
            "558 - Pakm!pple\n",
            "559 - Paltestin\n",
            "560 - Perfecto1\n",
            "561 - PHI235243\n",
            "562 - POISONWIN\n",
            "563 - PEPPERCAF\n",
            "564 - Paul_Boy1\n",
            "565 - Punchie69\n",
            "566 - PeRBITcH8\n",
            "567 - PEOPLEZ94\n",
            "568 - Pony-0922\n",
            "569 - PHAMZERTU\n",
            "570 - Purwante0\n",
            "571 - PACMANS36\n",
            "572 - Pluguinds\n",
            "573 - Poncho821\n",
            "574 - PWH198306\n",
            "575 - PACK7799X\n",
            "576 - PINKRAT19\n",
            "577 - Pin3way33\n",
            "578 - Pratt555g\n",
            "579 - PM9991311\n",
            "580 - Patsy1405\n",
            "581 - Peanut428\n",
            "582 - PUTAFLOR9\n",
            "583 - PEDOBETAM\n",
            "584 - PatuK3667\n",
            "585 - POMPIMILI\n",
            "586 - POPICEPSU\n",
            "587 - PW0088303\n",
            "588 - Philip138\n",
            "589 - Poly13!92\n",
            "590 - Presshous\n",
            "591 - PAPITL198\n",
            "592 - Piratesud\n",
            "593 - PrInCeSsB\n",
            "594 - P1O2R3I4R\n",
            "595 - PIPOLINA9\n",
            "596 - PREza123#\n",
            "597 - PENCILPET\n",
            "598 - Pre-Siane\n",
            "599 - PA_CKUTES\n",
            "600 - PHCaccrco\n",
            "601 - PAZ102750\n",
            "602 - Pinkypink\n",
            "603 - PULPEN042\n",
            "604 - Pr@D1995!\n",
            "605 - POriskool\n",
            "606 - PAUL49486\n",
            "607 - POLKADOT:\n",
            "608 - PB090805A\n",
            "609 - Picolopo2\n",
            "610 - Pr1nc3ss3\n",
            "611 - Pavillion\n",
            "612 - POWER8cmf\n",
            "613 - PHILM@STE\n",
            "614 - PKA224779\n",
            "615 - PJIP32721\n",
            "616 - Pioneer1f\n",
            "617 - PK14YOU25\n",
            "618 - Playgirl1\n",
            "619 - PQ2fY2gvJ\n",
            "620 - P01canBra\n",
            "621 - PaoliZi0t\n",
            "622 - Police77g\n",
            "623 - Panic67Su\n",
            "624 - PRINCEzzZ\n",
            "625 - PDPolice1\n",
            "626 - PAOPYLELA\n",
            "627 - POOHBEARN\n",
            "628 - PRECIOUS5\n",
            "629 - PrFeB2906\n",
            "630 - PEPEKTIND\n",
            "631 - PROECTOS1\n",
            "632 - PITUCASAR\n",
            "633 - PTB906607\n",
            "634 - Piacer120\n",
            "635 - PIIGLET15\n",
            "636 - PA_bi_zim\n",
            "637 - PIOLLA349\n",
            "638 - PODERNELI\n",
            "639 - POOHBEARK\n",
            "640 - POONS2652\n",
            "641 - PASSword0\n",
            "642 - Penn22568\n",
            "643 - Pratiwi20\n",
            "644 - PIESTAR12\n",
            "645 - PASSWORD5\n",
            "646 - Pig061969\n",
            "647 - Pipcake12\n",
            "648 - Pirate210\n",
            "649 - Princesa9\n",
            "650 - Piaggy555\n",
            "651 - Puts44Roc\n",
            "652 - Pour96072\n",
            "653 - PAKI EIMI\n",
            "654 - PIMPJRANT\n",
            "655 - PIIGPIG33\n",
            "656 - PAYYAT123\n",
            "657 - PRASERTY0\n",
            "658 - Perra1215\n",
            "659 - Philly430\n",
            "660 - Parky18ro\n",
            "661 - Pasture d\n",
            "662 - PIJEWEPHU\n",
            "663 - Peterkevi\n",
            "664 - PARKINA23\n",
            "665 - PROMETEME\n",
            "666 - POIZQUEZA\n",
            "667 - Pup475ix5\n",
            "668 - PasiTaDel\n",
            "669 - PINK03251\n",
            "670 - PassdPooh\n",
            "671 - POWER420J\n",
            "672 - PEDRariel\n",
            "673 - PENNY1902\n",
            "674 - Puffys332\n",
            "675 - PE3WPP4ZX\n",
            "676 - Pseueddra\n",
            "677 - Pinkpinks\n",
            "678 - P1NCHE.K3\n",
            "679 - PIGGIECAT\n",
            "680 - PLAYBOYJA\n",
            "681 - Purelife1\n",
            "682 - PPACEU123\n",
            "683 - Princess8\n",
            "684 - Password1\n",
            "Model took 684 attempts to find password - Password1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attempts calculation"
      ],
      "metadata": {
        "id": "kO3QyjGccp6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_attempts(given_pwd):\n",
        "  pass_len = len(given_pwd)\n",
        "  attempts = 1\n",
        "  # iterate through each starting letter. \n",
        "  for l in tokenizer.word_index.keys():\n",
        "    states = None\n",
        "    next_char = [l]\n",
        "    result = [next_char]\n",
        "\n",
        "    for n in range(pass_len-1):\n",
        "      next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "      result.append(next_char)\n",
        "    \n",
        "    result = tf.strings.join(result)\n",
        "    pred = result[0].numpy().decode('utf-8')\n",
        "    if pred == given_pwd:\n",
        "      print(f\"Model predicted password in {attempts}\")\n",
        "    else:\n",
        "      attempts += 1"
      ],
      "metadata": {
        "id": "c0NBDNfEczdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_attempts('war')"
      ],
      "metadata": {
        "id": "nKROvvHALrwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
        "\n",
        "reference = [['a', 'b', 'c'], ['p','q','r'],[' ']]\n",
        "candidate = [['a', 'b', 'c'], ['p','q','r'],[' ']]\n",
        "\n",
        "score = corpus_bleu(reference, candidate)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z--ji9x7qaGV",
        "outputId": "9490e691-3d3c-47ea-b575-b8ecc028adb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reference = [['a', 'b', 'c'], ['p','q','r'],[' ']]\n",
        "candidate = [['p','q','r'],['a', 'b', 'c'],[' ']]\n",
        "\n",
        "score = corpus_bleu(reference, candidate)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4KxdntdQs6Q",
        "outputId": "21b56216-63a8-4abb-8cbb-13c465c2a12b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6147881529512643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
        "reference = [['a', 'b', 'c'], ['p','q','r'],[' ']]\n",
        "candidate = [['a', 'b', 'd'], ['p','q','r'],[' ']]\n",
        "\n",
        "score = corpus_bleu(reference, candidate)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMwy4ZciQ84D",
        "outputId": "789d40df-04f8-45d3-e661-50f6f53916af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9621954581957615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lXdmupYARBQS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "train.ipynb",
      "provenance": [],
      "mount_file_id": "1pIF9C4bW_WnKnuibA8j8in6IlDc1saUB",
      "authorship_tag": "ABX9TyMeIm3SZRAg+Jaa5F8G99Cz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}